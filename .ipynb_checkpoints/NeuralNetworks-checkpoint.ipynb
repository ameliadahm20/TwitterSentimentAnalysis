{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataframe.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09520</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['swonderlin', 'not', 'wait', 'iPad', '2', 'al...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "      <td>swonderlin not wait iPad 2 also should sale do...</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.30550</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sxsw', 'hope', 'year', 'festival', 't', 'cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "      <td>sxsw hope year festival t crashy this year iPh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.841547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "      <td>sxtxstate great stuff Fri SXSW Marissa Mayer G...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55125</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.554026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet            product_  \\\n",
       "0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...              iPhone   \n",
       "1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...  iPad or iPhone App   \n",
       "2  ['swonderlin', 'not', 'wait', 'iPad', '2', 'al...                iPad   \n",
       "3  ['sxsw', 'hope', 'year', 'festival', 't', 'cra...  iPad or iPhone App   \n",
       "4  ['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...              Google   \n",
       "\n",
       "   emotion                                  lemmatizer_tweets  \\\n",
       "0        0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...   \n",
       "1        1  jessedee Know fludapp Awesome iPad iPhone app ...   \n",
       "2        1  swonderlin not wait iPad 2 also should sale do...   \n",
       "3        0  sxsw hope year festival t crashy this year iPh...   \n",
       "4        1  sxtxstate great stuff Fri SXSW Marissa Mayer G...   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  vs_neg  vs_neu  vs_pos  \\\n",
       "0          -0.200000               0.400000   0.223   0.777   0.000   \n",
       "1           0.466667               0.933333   0.000   0.528   0.472   \n",
       "2          -0.155556               0.288889   0.000   1.000   0.000   \n",
       "3           0.000000               0.000000   0.000   0.596   0.404   \n",
       "4           0.800000               0.750000   0.000   0.796   0.204   \n",
       "\n",
       "   vs_compound  nrc_sentiment  gi_sentiment  henry_sentiment  huliu_sentiment  \\\n",
       "0      -0.6486            0.0     -0.333333              0.0             -1.0   \n",
       "1       0.9100            1.0      1.000000              0.0              1.0   \n",
       "2       0.0000           -1.0     -1.000000             -1.0             -1.0   \n",
       "3       0.7269            1.0      1.000000              0.0              0.0   \n",
       "4       0.6249            0.0      1.000000              0.0              1.0   \n",
       "\n",
       "   jockers_sentiment  lm_sentiment  senticnet_sentiment  sentiword_sentiment  \\\n",
       "0          -1.000000           0.0             -0.09520            -0.221875   \n",
       "1           0.416667           0.0              0.47500             0.175000   \n",
       "2          -0.625000          -1.0             -0.30550            -0.289062   \n",
       "3           0.500000           0.0              0.07160             0.250000   \n",
       "4           0.500000           1.0              0.55125             0.083333   \n",
       "\n",
       "   socal_sentiment  \n",
       "0        -1.192154  \n",
       "1         2.177190  \n",
       "2        -1.000000  \n",
       "3         2.841547  \n",
       "4         1.554026  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'] = np.where(df['emotion'] == 4, 2, df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=['emotion', 'tweet', 'product_', 'lemmatizer_tweets'])\n",
    "target = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE( random_state=23)\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 15)\n",
      "(1819, 15)\n",
      "(7273,)\n",
      "(1819,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "910/910 [==============================] - 1s 956us/step - loss: 0.9356 - accuracy: 0.5904 - val_loss: 0.9089 - val_accuracy: 0.5910\n",
      "Epoch 2/15\n",
      "910/910 [==============================] - 1s 693us/step - loss: 0.8866 - accuracy: 0.6046 - val_loss: 0.8965 - val_accuracy: 0.6031\n",
      "Epoch 3/15\n",
      "910/910 [==============================] - 1s 680us/step - loss: 0.8781 - accuracy: 0.6121 - val_loss: 0.8939 - val_accuracy: 0.5965\n",
      "Epoch 4/15\n",
      "910/910 [==============================] - 1s 681us/step - loss: 0.8707 - accuracy: 0.6124 - val_loss: 0.8893 - val_accuracy: 0.6174\n",
      "Epoch 5/15\n",
      "910/910 [==============================] - 1s 673us/step - loss: 0.8605 - accuracy: 0.6143 - val_loss: 0.8881 - val_accuracy: 0.6086\n",
      "Epoch 6/15\n",
      "910/910 [==============================] - 1s 702us/step - loss: 0.8642 - accuracy: 0.6103 - val_loss: 0.8850 - val_accuracy: 0.6152\n",
      "Epoch 7/15\n",
      "910/910 [==============================] - 1s 676us/step - loss: 0.8574 - accuracy: 0.6182 - val_loss: 0.8874 - val_accuracy: 0.6185\n",
      "Epoch 8/15\n",
      "910/910 [==============================] - 1s 683us/step - loss: 0.8594 - accuracy: 0.6154 - val_loss: 0.8871 - val_accuracy: 0.6036\n",
      "Epoch 9/15\n",
      "910/910 [==============================] - 1s 686us/step - loss: 0.8577 - accuracy: 0.6117 - val_loss: 0.8852 - val_accuracy: 0.6124\n",
      "Epoch 10/15\n",
      "910/910 [==============================] - 1s 677us/step - loss: 0.8527 - accuracy: 0.6142 - val_loss: 0.8834 - val_accuracy: 0.6135\n",
      "Epoch 11/15\n",
      "910/910 [==============================] - 1s 684us/step - loss: 0.8503 - accuracy: 0.6174 - val_loss: 0.8833 - val_accuracy: 0.6113\n",
      "Epoch 12/15\n",
      "910/910 [==============================] - 1s 680us/step - loss: 0.8497 - accuracy: 0.6179 - val_loss: 0.8817 - val_accuracy: 0.6113\n",
      "Epoch 13/15\n",
      "910/910 [==============================] - 1s 709us/step - loss: 0.8501 - accuracy: 0.6171 - val_loss: 0.8847 - val_accuracy: 0.6135\n",
      "Epoch 14/15\n",
      "910/910 [==============================] - 1s 724us/step - loss: 0.8469 - accuracy: 0.6194 - val_loss: 0.8829 - val_accuracy: 0.6047\n",
      "Epoch 15/15\n",
      "910/910 [==============================] - 1s 686us/step - loss: 0.8456 - accuracy: 0.6182 - val_loss: 0.8822 - val_accuracy: 0.6201\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "# tl = TomekLinks()\n",
    "# X_train, y_train = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(1738, 15)\n",
    "# X_test = X_test.reshape(1819, 15)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the fourth layer\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the 5th layer\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8821552395820618\n",
      "Test accuracy: 0.6201209425926208\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
