{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce project ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.probability import FreqDist # looks at how frequent words are used\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestClassifier #\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in tweets\n",
    "# src: https://data.world/crowdflower/brands-and-product-emotions\n",
    "df = pd.read_csv('data/tweets.csv', encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns ={'tweet_text': 'tweet',\n",
    "                    'emotion_in_tweet_is_directed_at': 'product_',\n",
    "                    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could make the nulls for products into 'Other' category\n",
    "\n",
    "# put null values into other category\n",
    "df['product_'] = np.where(df['product_'].isnull(), 'Unknown', df['product_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the one null tweet\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable\n",
    "# I CANT TELL whattt\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target varible numbers\n",
    "df['emotion'] = np.where(df['emotion'] == \"I can't tell\", 4, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'No emotion toward brand or product', 3, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Positive emotion', 1, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Negative emotion', 0, df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data type\n",
    "df['emotion'] = df['emotion'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words in tweets using regex\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "items = []\n",
    "for item in df['tweet']:\n",
    "    item = tokenizer.tokenize(item)\n",
    "    items.append(item)\n",
    "    \n",
    "df['tweet'] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stop wordset\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166994\n"
     ]
    }
   ],
   "source": [
    "# Before stop word removal\n",
    "before = 0\n",
    "for item in df['tweet']:\n",
    "    for obj in item:\n",
    "        before +=1\n",
    "print(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to remove stop words\n",
    "removed_stop = []\n",
    "for row in df['tweet']:\n",
    "    for item in row:\n",
    "        if item.lower() in stop_words:\n",
    "            row.remove(item)\n",
    "    removed_stop.append(row)\n",
    "df['tweet'] = removed_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166994\n",
      "126936\n"
     ]
    }
   ],
   "source": [
    "# After stop word removal\n",
    "after = 0\n",
    "for item in df['tweet']:\n",
    "    for obj in item:\n",
    "        after +=1\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "\n",
    "# stemmed_tweets=[]\n",
    "# for row in df['tweet']:\n",
    "#     new_row = []\n",
    "#     for w in row:\n",
    "#         new_row.append(ps.stem(w))\n",
    "#     stemmed_tweets.append(new_row)\n",
    "        \n",
    "# df['stemmed_tweets'] =  stemmed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "lemmatizer_tweets=[]\n",
    "for row in df['tweet']:\n",
    "    new_row = []\n",
    "    for w in row:\n",
    "        new_row.append(lemmatizer.lemmatize(w))\n",
    "    lemmatizer_tweets.append(new_row)\n",
    "        \n",
    "df['lemmatizer_tweets'] =  lemmatizer_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley83, have, 3G, iPhone, 3, hr, tweeting, ...\n",
       "1       [jessedee, Know, fludapp, Awesome, iPad, iPhon...\n",
       "2       [swonderlin, not, wait, iPad, 2, also, should,...\n",
       "3       [sxsw, hope, year, festival, t, crashy, this, ...\n",
       "4       [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...\n",
       "                              ...                        \n",
       "9088                       [Ipad, everywhere, SXSW, link]\n",
       "9089    [Wave, buzz, RT, mention, interrupt, regularly...\n",
       "9090    [Google, Zeiger, physician, never, reported, p...\n",
       "9091    [Verizon, iPhone, customer, complained, time, ...\n",
       "9092    [RT, mention, Google, Tests, Check, Offers, SX...\n",
       "Name: lemmatizer_tweets, Length: 9092, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatizer_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat words in tweet series\n",
    "new_lem_tweets = []\n",
    "for item in df['lemmatizer_tweets']:\n",
    "    obj = ''\n",
    "    for w in item:\n",
    "        obj = obj + w + ' '\n",
    "    new_lem_tweets.append(obj)\n",
    "\n",
    "df['lemmatizer_tweets'] = new_lem_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03948607, 0.29783715, 0.33552922, ..., 0.17821177, 0.1847066 ,\n",
       "       0.08015913])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using this as the data target had better performance\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(df['lemmatizer_tweets'])\n",
    "text_tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    analysis = TextBlob(tweet)\n",
    "    polar = analysis.sentiment.polarity\n",
    "    sub = analysis.sentiment.subjectivity\n",
    "    polarity.append(polar)\n",
    "    subjectivity.append(sub)\n",
    "    \n",
    "df['textblob_polarity'] = polarity\n",
    "df['textblob_subjectivity'] = subjectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "vs_neg = []\n",
    "vs_neu = []\n",
    "vs_pos = []\n",
    "vs_compund = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    neg = vs['neg']\n",
    "    neu = vs['neu']\n",
    "    pos = vs['pos']\n",
    "    compound = vs['compound']\n",
    "    \n",
    "    vs_neg.append(neg)\n",
    "    vs_neu.append(neu)\n",
    "    vs_pos.append(pos)\n",
    "    vs_compund.append(compound)\n",
    "\n",
    "    \n",
    "df['vs_neg'] = vs_neg\n",
    "df['vs_neu'] = vs_neu\n",
    "df['vs_pos'] = vs_pos\n",
    "df['vs_compound'] = vs_compund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sentiments from varying libraries\n",
    "\n",
    "# This takes 25 minutes to run\n",
    "# import py_files.sentiment_lib as sent\n",
    "# df = sent.get_sentiment(df)\n",
    "# df.to_csv('dataframe.csv')\n",
    "\n",
    "df = pd.read_csv('data/dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0952</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  \\\n",
       "0           0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...   \n",
       "1           1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...   \n",
       "\n",
       "             product_  emotion  \\\n",
       "0              iPhone        0   \n",
       "1  iPad or iPhone App        1   \n",
       "\n",
       "                                   lemmatizer_tweets  textblob_polarity  \\\n",
       "0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...          -0.200000   \n",
       "1  jessedee Know fludapp Awesome iPad iPhone app ...           0.466667   \n",
       "\n",
       "   textblob_subjectivity  vs_neg  vs_neu  vs_pos  vs_compound  nrc_sentiment  \\\n",
       "0               0.400000   0.223   0.777   0.000      -0.6486            0.0   \n",
       "1               0.933333   0.000   0.528   0.472       0.9100            1.0   \n",
       "\n",
       "   gi_sentiment  henry_sentiment  huliu_sentiment  jockers_sentiment  \\\n",
       "0     -0.333333              0.0             -1.0          -1.000000   \n",
       "1      1.000000              0.0              1.0           0.416667   \n",
       "\n",
       "   lm_sentiment  senticnet_sentiment  sentiword_sentiment  socal_sentiment  \n",
       "0           0.0              -0.0952            -0.221875        -1.192154  \n",
       "1           0.0               0.4750             0.175000         2.177190  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['lemmatizer_tweets']\n",
    "target = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all lemmatized outputs\n",
    "lemmatized_output = []\n",
    "\n",
    "for listy in data:\n",
    "    lemmed = ''.join([w for w in listy])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = lemmatized_output\n",
    "y_lem = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split the lemmatized words\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.20, random_state=1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_words)\n",
    "\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.721297951326825\n",
      "0.9994709702681942\n"
     ]
    }
   ],
   "source": [
    "# Average Number of Non-Zero Elements in Vectorized Tweets\n",
    "non_zero_cols = tfidf_data_train_lem.nnz / float(tfidf_data_train_lem.shape[0])\n",
    "print(non_zero_cols)\n",
    "\n",
    "# Percentage of columns containing ZERO\n",
    "percent_sparse = 1 - (non_zero_cols / float(tfidf_data_train_lem.shape[1]))\n",
    "print(percent_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lem = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_lem.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_preds_lem = rf_lem.predict(tfidf_data_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6564046179219352\n",
      "Precision: 0.6520620811425643\n",
      "Recall: 0.6564046179219352\n",
      "F1: 0.6146255927247407\n"
     ]
    }
   ],
   "source": [
    "rf_acc_score_lem = metrics.accuracy_score(y_test_lem, rf_test_preds_lem)\n",
    "rf_f1_score_lem = metrics.f1_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_precision_score_lem = metrics.precision_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_recall_score_lem = metrics.recall_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "print('Accuracy:', rf_acc_score_lem)\n",
    "print('Precision:',rf_precision_score_lem)\n",
    "print('Recall:',rf_recall_score_lem)\n",
    "print('F1:',rf_f1_score_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
