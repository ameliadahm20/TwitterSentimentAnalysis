{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce project ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.probability import FreqDist # looks at how frequent words are used\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestClassifier #\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string, re\n",
    "string.punctuation\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in tweets\n",
    "# src: https://data.world/crowdflower/brands-and-product-emotions\n",
    "df = pd.read_csv('data/tweets.csv', encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns ={'tweet_text': 'tweet',\n",
    "                    'emotion_in_tweet_is_directed_at': 'product_',\n",
    "                    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could make the nulls for products into 'Other' category\n",
    "\n",
    "# put null values into other category\n",
    "df['product_'] = np.where(df['product_'].isnull(), 'Unknown', df['product_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the one null tweet\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable\n",
    "# I CANT TELL whattt\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target varible numbers\n",
    "df['emotion'] = np.where(df['emotion'] == \"I can't tell\", 2, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'No emotion toward brand or product', 3, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Positive emotion', 1, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Negative emotion', 0, df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data type\n",
    "df['emotion'] = df['emotion'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenize words in tweets using regex\n",
    "# tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# items = []\n",
    "# for item in df['tweet']:\n",
    "#     item = tokenizer.tokenize(item)\n",
    "#     items.append(item)\n",
    "    \n",
    "# df['tweet'] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stop wordset\n",
    "# stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting stopwords and punctuations\n",
    "stop_words=stopwords.words(\"english\")\n",
    "stop_words += list(string.punctuation)\n",
    "stop_words += ['...','u','w','2',\"i'm\",'via',\"we're\",'6','3','hey']\n",
    "# print(stop_words)\n",
    "sw_set = set(stop_words)\n",
    "# sw_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    tokenizer = RegexpTokenizer(r\"(iPad\\s2|[a-zA-Z0-9-]+'?\\w+)\")\n",
    "\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    sw_removed = [token.lower().replace(\" \",\"\") for token in tokens if token.lower() not in sw_set]\n",
    "    return sw_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went', 'store']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = 'i went to the store'\n",
    "process_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet            product_  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "...                                                 ...                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}                iPad   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...             Unknown   \n",
       "9090  Google's Zeiger, a physician never reported po...             Unknown   \n",
       "9091  Some Verizon iPhone customers complained their...             Unknown   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...             Unknown   \n",
       "\n",
       "      emotion  \n",
       "0           0  \n",
       "1           1  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "9088        1  \n",
       "9089        3  \n",
       "9090        3  \n",
       "9091        3  \n",
       "9092        3  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in df['tweet']:\n",
    "    item = process_tweet(item)\n",
    "    items.append(item)\n",
    "df['tweet'] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wesley83, 3g, iphone, hrs, tweeting, rise_aus...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[jessedee, know, fludapp, awesome, ipad, iphon...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[swonderlin, wait, ipad2, also, sale, sxsw]</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sxsw, hope, year's, festival, crashy, year's,...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>[ipad, everywhere, sxsw, link]</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>[wave, buzz, rt, mention, interrupt, regularly...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>[google's, zeiger, physician, never, reported,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>[verizon, iphone, customers, complained, time,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>[rt, mention, google, tests, check-in, offers,...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet            product_  \\\n",
       "0     [wesley83, 3g, iphone, hrs, tweeting, rise_aus...              iPhone   \n",
       "1     [jessedee, know, fludapp, awesome, ipad, iphon...  iPad or iPhone App   \n",
       "2           [swonderlin, wait, ipad2, also, sale, sxsw]                iPad   \n",
       "3     [sxsw, hope, year's, festival, crashy, year's,...  iPad or iPhone App   \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...              Google   \n",
       "...                                                 ...                 ...   \n",
       "9088                     [ipad, everywhere, sxsw, link]                iPad   \n",
       "9089  [wave, buzz, rt, mention, interrupt, regularly...             Unknown   \n",
       "9090  [google's, zeiger, physician, never, reported,...             Unknown   \n",
       "9091  [verizon, iphone, customers, complained, time,...             Unknown   \n",
       "9092  [rt, mention, google, tests, check-in, offers,...             Unknown   \n",
       "\n",
       "      emotion  \n",
       "0           0  \n",
       "1           1  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "9088        1  \n",
       "9089        3  \n",
       "9090        3  \n",
       "9091        3  \n",
       "9092        3  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "\n",
    "# stemmed_tweets=[]\n",
    "# for row in df['tweet']:\n",
    "#     new_row = []\n",
    "#     for w in row:\n",
    "#         new_row.append(ps.stem(w))\n",
    "#     stemmed_tweets.append(new_row)\n",
    "        \n",
    "# df['stemmed_tweets'] =  stemmed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "lemmatizer_tweets=[]\n",
    "for row in df['tweet']:\n",
    "    new_row = []\n",
    "    for w in row:\n",
    "        new_row.append(lemmatizer.lemmatize(w))\n",
    "    lemmatizer_tweets.append(new_row)\n",
    "        \n",
    "df['lemmatizer_tweets'] =  lemmatizer_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley83, 3g, iphone, hr, tweeting, rise_aust...\n",
       "1       [jessedee, know, fludapp, awesome, ipad, iphon...\n",
       "2             [swonderlin, wait, ipad2, also, sale, sxsw]\n",
       "3       [sxsw, hope, year's, festival, crashy, year's,...\n",
       "4       [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "                              ...                        \n",
       "9088                       [ipad, everywhere, sxsw, link]\n",
       "9089    [wave, buzz, rt, mention, interrupt, regularly...\n",
       "9090    [google's, zeiger, physician, never, reported,...\n",
       "9091    [verizon, iphone, customer, complained, time, ...\n",
       "9092    [rt, mention, google, test, check-in, offer, s...\n",
       "Name: lemmatizer_tweets, Length: 9092, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatizer_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat words in tweet series\n",
    "new_lem_tweets = []\n",
    "for item in df['lemmatizer_tweets']:\n",
    "    obj = ''\n",
    "    for w in item:\n",
    "        obj = obj + w + ' '\n",
    "    new_lem_tweets.append(obj)\n",
    "\n",
    "df['lemmatizer_tweets'] = new_lem_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04098343, 0.30909751, 0.3482146 , ..., 0.17451905, 0.1808793 ,\n",
       "       0.07850679])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using this as the data target had better performance\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(df['lemmatizer_tweets'])\n",
    "text_tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    analysis = TextBlob(tweet)\n",
    "    polar = analysis.sentiment.polarity\n",
    "    sub = analysis.sentiment.subjectivity\n",
    "    polarity.append(polar)\n",
    "    subjectivity.append(sub)\n",
    "    \n",
    "df['textblob_polarity'] = polarity\n",
    "df['textblob_subjectivity'] = subjectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "vs_neg = []\n",
    "vs_neu = []\n",
    "vs_pos = []\n",
    "vs_compund = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    neg = vs['neg']\n",
    "    neu = vs['neu']\n",
    "    pos = vs['pos']\n",
    "    compound = vs['compound']\n",
    "    \n",
    "    vs_neg.append(neg)\n",
    "    vs_neu.append(neu)\n",
    "    vs_pos.append(pos)\n",
    "    vs_compund.append(compound)\n",
    "\n",
    "    \n",
    "df['vs_neg'] = vs_neg\n",
    "df['vs_neu'] = vs_neu\n",
    "df['vs_pos'] = vs_pos\n",
    "df['vs_compound'] = vs_compund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sentiments from varying libraries\n",
    "\n",
    "# This takes 25 minutes to run\n",
    "import py_files.sentiment_lib as sent\n",
    "df = sent.get_sentiment(df)\n",
    "df.to_csv('dataframe.csv')\n",
    "\n",
    "df = pd.read_csv('data/dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['lemmatizer_tweets']\n",
    "target = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all lemmatized outputs\n",
    "lemmatized_output = []\n",
    "\n",
    "for listy in data:\n",
    "    lemmed = ''.join([w for w in listy])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = lemmatized_output\n",
    "y_lem = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split the lemmatized words\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.20, random_state=1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_words)\n",
    "\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Number of Non-Zero Elements in Vectorized Tweets\n",
    "non_zero_cols = tfidf_data_train_lem.nnz / float(tfidf_data_train_lem.shape[0])\n",
    "print(non_zero_cols)\n",
    "\n",
    "# Percentage of columns containing ZERO\n",
    "percent_sparse = 1 - (non_zero_cols / float(tfidf_data_train_lem.shape[1]))\n",
    "print(percent_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lem = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lem.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_preds_lem = rf_lem.predict(tfidf_data_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc_score_lem = metrics.accuracy_score(y_test_lem, rf_test_preds_lem)\n",
    "rf_f1_score_lem = metrics.f1_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_precision_score_lem = metrics.precision_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_recall_score_lem = metrics.recall_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "print('Accuracy:', rf_acc_score_lem)\n",
    "print('Precision:',rf_precision_score_lem)\n",
    "print('Recall:',rf_recall_score_lem)\n",
    "print('F1:',rf_f1_score_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
