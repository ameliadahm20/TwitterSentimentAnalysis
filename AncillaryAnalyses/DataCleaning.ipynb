{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in tweets\n",
    "# src: https://data.world/crowdflower/brands-and-product-emotions\n",
    "df = pd.read_csv('../data/tweets.csv', encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns ={'tweet_text': 'tweet',\n",
    "                    'emotion_in_tweet_is_directed_at': 'product_',\n",
    "                    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put null values into other category\n",
    "df['product_'] = np.where(df['product_'].isnull(), 'Unknown', df['product_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the one null tweet\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target varible numbers\n",
    "df['emotion'] = np.where(df['emotion'] == \"I can't tell\", 2, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'No emotion toward brand or product', 3, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Positive emotion', 1, df['emotion'])\n",
    "df['emotion'] = np.where(df['emotion'] == 'Negative emotion', 0, df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data type\n",
    "df['emotion'] = df['emotion'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting stopwords and punctuations\n",
    "stop_words=stopwords.words(\"english\")\n",
    "stop_words += list(string.punctuation)\n",
    "stop_words += ['...','u','w','2',\"i'm\",'via',\"we're\",'6','3','hey']\n",
    "# print(stop_words)\n",
    "sw_set = set(stop_words)\n",
    "# sw_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    tokenizer = RegexpTokenizer(r\"(iPad\\s2|[a-zA-Z0-9-]+'?\\w+)\")\n",
    "\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    sw_removed = [token.lower().replace(\" \",\"\") for token in tokens if token.lower() not in sw_set]\n",
    "    return sw_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in df['tweet']:\n",
    "    item = process_tweet(item)\n",
    "    items.append(item)\n",
    "df['tweet'] = items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "\n",
    "# stemmed_tweets=[]\n",
    "# for row in df['tweet']:\n",
    "#     new_row = []\n",
    "#     for w in row:\n",
    "#         new_row.append(ps.stem(w))\n",
    "#     stemmed_tweets.append(new_row)\n",
    "        \n",
    "# df['stemmed_tweets'] =  stemmed_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "lemmatizer_tweets=[]\n",
    "for row in df['tweet']:\n",
    "    new_row = []\n",
    "    for w in row:\n",
    "        new_row.append(lemmatizer.lemmatize(w))\n",
    "    lemmatizer_tweets.append(new_row)\n",
    "        \n",
    "df['lemmatizer_tweets'] =  lemmatizer_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [wesley83, 3g, iphone, hr, tweeting, rise_aust...\n",
       "1    [jessedee, know, fludapp, awesome, ipad, iphon...\n",
       "2          [swonderlin, wait, ipad2, also, sale, sxsw]\n",
       "3    [sxsw, hope, year's, festival, crashy, year's,...\n",
       "4    [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "Name: lemmatizer_tweets, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatizer_tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat words in tweet series\n",
    "new_lem_tweets = []\n",
    "for item in df['lemmatizer_tweets']:\n",
    "    obj = ''\n",
    "    for w in item:\n",
    "        obj = obj + w + ' '\n",
    "    new_lem_tweets.append(obj)\n",
    "\n",
    "df['lemmatizer_tweets'] = new_lem_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04098343, 0.30909751, 0.3482146 , ..., 0.17451905, 0.1808793 ,\n",
       "       0.07850679])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using this as the data target had better performance\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(df['lemmatizer_tweets'])\n",
    "text_tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob and VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    analysis = TextBlob(tweet)\n",
    "    polar = analysis.sentiment.polarity\n",
    "    sub = analysis.sentiment.subjectivity\n",
    "    polarity.append(polar)\n",
    "    subjectivity.append(sub)\n",
    "    \n",
    "df['textblob_polarity'] = polarity\n",
    "df['textblob_subjectivity'] = subjectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "vs_neg = []\n",
    "vs_neu = []\n",
    "vs_pos = []\n",
    "vs_compund = []\n",
    "for tweet in df['lemmatizer_tweets']:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    neg = vs['neg']\n",
    "    neu = vs['neu']\n",
    "    pos = vs['pos']\n",
    "    compound = vs['compound']\n",
    "    \n",
    "    vs_neg.append(neg)\n",
    "    vs_neu.append(neu)\n",
    "    vs_pos.append(pos)\n",
    "    vs_compund.append(compound)\n",
    "\n",
    "    \n",
    "df['vs_neg'] = vs_neg\n",
    "df['vs_neu'] = vs_neu\n",
    "df['vs_pos'] = vs_pos\n",
    "df['vs_compound'] = vs_compund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sentiments from varying libraries\n",
    "\n",
    "# This takes 25 minutes to run\n",
    "# import py_files.sentiment_lib as sent\n",
    "# df = sent.get_sentiment(df)\n",
    "# df.to_csv('dataframe.csv')\n",
    "\n",
    "df = pd.read_csv('../data/dataframe.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0952</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet            product_  \\\n",
       "0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...              iPhone   \n",
       "1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...  iPad or iPhone App   \n",
       "\n",
       "   emotion                                  lemmatizer_tweets  \\\n",
       "0        0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...   \n",
       "1        1  jessedee Know fludapp Awesome iPad iPhone app ...   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  vs_neg  vs_neu  vs_pos  \\\n",
       "0          -0.200000               0.400000   0.223   0.777   0.000   \n",
       "1           0.466667               0.933333   0.000   0.528   0.472   \n",
       "\n",
       "   vs_compound  nrc_sentiment  gi_sentiment  henry_sentiment  huliu_sentiment  \\\n",
       "0      -0.6486            0.0     -0.333333              0.0             -1.0   \n",
       "1       0.9100            1.0      1.000000              0.0              1.0   \n",
       "\n",
       "   jockers_sentiment  lm_sentiment  senticnet_sentiment  sentiword_sentiment  \\\n",
       "0          -1.000000           0.0              -0.0952            -0.221875   \n",
       "1           0.416667           0.0               0.4750             0.175000   \n",
       "\n",
       "   socal_sentiment  \n",
       "0        -1.192154  \n",
       "1         2.177190  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
