{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.probability import FreqDist # looks at how frequent words are used\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0952</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet            product_  \\\n",
       "0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...              iPhone   \n",
       "1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...  iPad or iPhone App   \n",
       "\n",
       "   emotion                                  lemmatizer_tweets  \\\n",
       "0        0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...   \n",
       "1        1  jessedee Know fludapp Awesome iPad iPhone app ...   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  vs_neg  vs_neu  vs_pos  \\\n",
       "0          -0.200000               0.400000   0.223   0.777   0.000   \n",
       "1           0.466667               0.933333   0.000   0.528   0.472   \n",
       "\n",
       "   vs_compound  nrc_sentiment  gi_sentiment  henry_sentiment  huliu_sentiment  \\\n",
       "0      -0.6486            0.0     -0.333333              0.0             -1.0   \n",
       "1       0.9100            1.0      1.000000              0.0              1.0   \n",
       "\n",
       "   jockers_sentiment  lm_sentiment  senticnet_sentiment  sentiword_sentiment  \\\n",
       "0          -1.000000           0.0              -0.0952            -0.221875   \n",
       "1           0.416667           0.0               0.4750             0.175000   \n",
       "\n",
       "   socal_sentiment  \n",
       "0        -1.192154  \n",
       "1         2.177190  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dataframe.csv', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting stopwords and punctuations\n",
    "stop_words=stopwords.words(\"english\")\n",
    "stop_words += list(string.punctuation)\n",
    "stop_words += ['...','u','w','2',\"i'm\",'via',\"we're\",'6','3','hey']\n",
    "sw_set = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = df[df.emotion==0]\n",
    "pos = df[df.emotion==1]\n",
    "idk = df[df.emotion==4]\n",
    "neu = df[df.emotion==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample negative\n",
    "neg_upsampled = resample(neg,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(neu), # match number in majority class\n",
    "                          random_state=23) # reproducible results\n",
    "\n",
    "# upsample positive\n",
    "pos_upsampled = resample(pos,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(neu), # match number in majority class\n",
    "                          random_state=23) # reproducible results\n",
    "\n",
    "# upsample unclear\n",
    "idk_upsampled = resample(idk,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(neu), # match number in majority class\n",
    "                          random_state=23) # reproducible results\n",
    "\n",
    "upsampled = pd.concat([neu, neg_upsampled, pos_upsampled, idk_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all lemmatized outputs\n",
    "data = upsampled['lemmatizer_tweets']\n",
    "lemmatized_output = []\n",
    "\n",
    "for listy in data:\n",
    "    lemmed = ''.join([w for w in listy])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y\n",
    "X_lem = lemmatized_output\n",
    "y_lem = upsampled['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split the lemmatized words\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.20, random_state=1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), stop_words=stop_words)\n",
    "\n",
    "# fit and transform\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.46952032944725\n",
      "0.9994795107637376\n"
     ]
    }
   ],
   "source": [
    "# Average number of non-zero elements in vectorized tweets\n",
    "non_zero_cols = tfidf_data_train_lem.nnz / float(tfidf_data_train_lem.shape[0])\n",
    "print(non_zero_cols)\n",
    "\n",
    "# Percentage of columns containing zero\n",
    "percent_sparse = 1 - (non_zero_cols / float(tfidf_data_train_lem.shape[1]))\n",
    "print(percent_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lem = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_lem.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_preds_lem = rf_lem.predict(tfidf_data_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9220598469032707\n",
      "Precision: 0.9210386351303297\n",
      "Recall: 0.9220598469032707\n",
      "F1: 0.9212052860626472\n"
     ]
    }
   ],
   "source": [
    "rf_acc_score_lem = metrics.accuracy_score(y_test_lem, rf_test_preds_lem)\n",
    "rf_f1_score_lem = metrics.f1_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_precision_score_lem = metrics.precision_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "rf_recall_score_lem = metrics.recall_score(y_test_lem, rf_test_preds_lem, average='weighted')\n",
    "print('Accuracy:', rf_acc_score_lem)\n",
    "print('Precision:',rf_precision_score_lem)\n",
    "print('Recall:',rf_recall_score_lem)\n",
    "print('F1:',rf_f1_score_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [150, 200],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [8],\n",
    "    'criterion' :['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [8],\n",
       "                         'max_features': ['auto'], 'n_estimators': [150, 200]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6670137414994359\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}\n",
      "RandomForestClassifier(max_depth=8, n_estimators=200, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 150],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [8,12],\n",
    "    'criterion' :['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [8, 12],\n",
       "                         'max_features': ['auto'], 'n_estimators': [100, 150]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007704576934436\n",
      "{'criterion': 'gini', 'max_depth': 12, 'max_features': 'auto', 'n_estimators': 150}\n",
      "RandomForestClassifier(max_depth=12, n_estimators=150, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [140, 150, 160],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [12],\n",
    "    'criterion' :['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [12],\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [140, 150, 160]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007704576934436\n",
      "{'criterion': 'gini', 'max_depth': 12, 'max_features': 'auto', 'n_estimators': 150}\n",
      "RandomForestClassifier(max_depth=12, n_estimators=150, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [138, 140, 142],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : [12],\n",
    "    'criterion' :['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [12],\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [138, 140, 142]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6987404298229623\n",
      "{'criterion': 'gini', 'max_depth': 12, 'max_features': 'auto', 'n_estimators': 142}\n",
      "RandomForestClassifier(max_depth=12, n_estimators=142, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': list(range(135,140)),\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : list(range(10,20)),\n",
    "    'criterion' :['gini']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini'],\n",
       "                         'max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [135, 136, 137, 138, 139]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7514052628994315\n",
      "{'criterion': 'gini', 'max_depth': 19, 'max_features': 'auto', 'n_estimators': 139}\n",
      "RandomForestClassifier(max_depth=19, n_estimators=139, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': list(range(137,139)),\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth' : list(range(17,25)),\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [17, 18, 19, 20, 21, 22, 23, 24],\n",
       "                         'max_features': ['auto'], 'n_estimators': [137, 138]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(tfidf_data_train_lem, y_train_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950220616083616\n",
      "{'criterion': 'entropy', 'max_depth': 24, 'max_features': 'auto', 'n_estimators': 137}\n",
      "RandomForestClassifier(criterion='entropy', max_depth=24, n_estimators=137,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
