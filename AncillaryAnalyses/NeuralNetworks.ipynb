{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09520</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['swonderlin', 'not', 'wait', 'iPad', '2', 'al...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "      <td>swonderlin not wait iPad 2 also should sale do...</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.30550</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sxsw', 'hope', 'year', 'festival', 't', 'cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "      <td>sxsw hope year festival t crashy this year iPh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.841547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "      <td>sxtxstate great stuff Fri SXSW Marissa Mayer G...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55125</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.554026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet            product_  \\\n",
       "0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...              iPhone   \n",
       "1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...  iPad or iPhone App   \n",
       "2  ['swonderlin', 'not', 'wait', 'iPad', '2', 'al...                iPad   \n",
       "3  ['sxsw', 'hope', 'year', 'festival', 't', 'cra...  iPad or iPhone App   \n",
       "4  ['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...              Google   \n",
       "\n",
       "   emotion                                  lemmatizer_tweets  \\\n",
       "0        0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...   \n",
       "1        1  jessedee Know fludapp Awesome iPad iPhone app ...   \n",
       "2        1  swonderlin not wait iPad 2 also should sale do...   \n",
       "3        0  sxsw hope year festival t crashy this year iPh...   \n",
       "4        1  sxtxstate great stuff Fri SXSW Marissa Mayer G...   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  vs_neg  vs_neu  vs_pos  \\\n",
       "0          -0.200000               0.400000   0.223   0.777   0.000   \n",
       "1           0.466667               0.933333   0.000   0.528   0.472   \n",
       "2          -0.155556               0.288889   0.000   1.000   0.000   \n",
       "3           0.000000               0.000000   0.000   0.596   0.404   \n",
       "4           0.800000               0.750000   0.000   0.796   0.204   \n",
       "\n",
       "   vs_compound  nrc_sentiment  gi_sentiment  henry_sentiment  huliu_sentiment  \\\n",
       "0      -0.6486            0.0     -0.333333              0.0             -1.0   \n",
       "1       0.9100            1.0      1.000000              0.0              1.0   \n",
       "2       0.0000           -1.0     -1.000000             -1.0             -1.0   \n",
       "3       0.7269            1.0      1.000000              0.0              0.0   \n",
       "4       0.6249            0.0      1.000000              0.0              1.0   \n",
       "\n",
       "   jockers_sentiment  lm_sentiment  senticnet_sentiment  sentiword_sentiment  \\\n",
       "0          -1.000000           0.0             -0.09520            -0.221875   \n",
       "1           0.416667           0.0              0.47500             0.175000   \n",
       "2          -0.625000          -1.0             -0.30550            -0.289062   \n",
       "3           0.500000           0.0              0.07160             0.250000   \n",
       "4           0.500000           1.0              0.55125             0.083333   \n",
       "\n",
       "   socal_sentiment  \n",
       "0        -1.192154  \n",
       "1         2.177190  \n",
       "2        -1.000000  \n",
       "3         2.841547  \n",
       "4         1.554026  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('../data/dataframe.csv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update output\n",
    "df['emotion'] = np.where(df['emotion'] == 4, 2, df['emotion'])\n",
    "# specify data and target\n",
    "data = df.drop(columns=['emotion', 'tweet', 'product_', 'lemmatizer_tweets'])\n",
    "target = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 15)\n",
      "(1819, 15)\n",
      "(7273,)\n",
      "(1819,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "# look at shpae of input\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "910/910 [==============================] - 1s 958us/step - loss: 0.9467 - accuracy: 0.5919 - val_loss: 0.9084 - val_accuracy: 0.5882\n",
      "Epoch 2/15\n",
      "910/910 [==============================] - 1s 757us/step - loss: 0.8906 - accuracy: 0.6002 - val_loss: 0.8972 - val_accuracy: 0.5970\n",
      "Epoch 3/15\n",
      "910/910 [==============================] - 1s 761us/step - loss: 0.8796 - accuracy: 0.6046 - val_loss: 0.8925 - val_accuracy: 0.6047\n",
      "Epoch 4/15\n",
      "910/910 [==============================] - 1s 899us/step - loss: 0.8722 - accuracy: 0.6075 - val_loss: 0.8922 - val_accuracy: 0.6064\n",
      "Epoch 5/15\n",
      "910/910 [==============================] - 1s 792us/step - loss: 0.8701 - accuracy: 0.6077 - val_loss: 0.8919 - val_accuracy: 0.6113\n",
      "Epoch 6/15\n",
      "910/910 [==============================] - 1s 728us/step - loss: 0.8624 - accuracy: 0.6125 - val_loss: 0.8895 - val_accuracy: 0.6080\n",
      "Epoch 7/15\n",
      "910/910 [==============================] - 1s 749us/step - loss: 0.8598 - accuracy: 0.6117 - val_loss: 0.8915 - val_accuracy: 0.6119\n",
      "Epoch 8/15\n",
      "910/910 [==============================] - 1s 723us/step - loss: 0.8611 - accuracy: 0.6136 - val_loss: 0.8943 - val_accuracy: 0.6086\n",
      "Epoch 9/15\n",
      "910/910 [==============================] - 1s 746us/step - loss: 0.8580 - accuracy: 0.6201 - val_loss: 0.8861 - val_accuracy: 0.6113\n",
      "Epoch 10/15\n",
      "910/910 [==============================] - 1s 766us/step - loss: 0.8556 - accuracy: 0.6169 - val_loss: 0.8849 - val_accuracy: 0.6053\n",
      "Epoch 11/15\n",
      "910/910 [==============================] - 1s 789us/step - loss: 0.8534 - accuracy: 0.6149 - val_loss: 0.8868 - val_accuracy: 0.6108\n",
      "Epoch 12/15\n",
      "910/910 [==============================] - 1s 824us/step - loss: 0.8538 - accuracy: 0.6135 - val_loss: 0.8875 - val_accuracy: 0.6080\n",
      "Epoch 13/15\n",
      "910/910 [==============================] - 1s 814us/step - loss: 0.8536 - accuracy: 0.6169 - val_loss: 0.8834 - val_accuracy: 0.6080\n",
      "Epoch 14/15\n",
      "910/910 [==============================] - 1s 780us/step - loss: 0.8511 - accuracy: 0.6194 - val_loss: 0.8875 - val_accuracy: 0.6053\n",
      "Epoch 15/15\n",
      "910/910 [==============================] - 1s 755us/step - loss: 0.8498 - accuracy: 0.6154 - val_loss: 0.8883 - val_accuracy: 0.6025\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8883348703384399\n",
      "Test accuracy: 0.6025288701057434\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization tool\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"Sentiment Neural Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 2: Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "762/762 [==============================] - 1s 1ms/step - loss: 0.9277 - accuracy: 0.6168 - val_loss: 0.9178 - val_accuracy: 0.5805\n",
      "Epoch 2/15\n",
      "762/762 [==============================] - 1s 830us/step - loss: 0.8600 - accuracy: 0.6297 - val_loss: 0.8981 - val_accuracy: 0.6058\n",
      "Epoch 3/15\n",
      "762/762 [==============================] - 1s 848us/step - loss: 0.8424 - accuracy: 0.6394 - val_loss: 0.8981 - val_accuracy: 0.6086\n",
      "Epoch 4/15\n",
      "762/762 [==============================] - 1s 804us/step - loss: 0.8415 - accuracy: 0.6365 - val_loss: 0.8951 - val_accuracy: 0.6152\n",
      "Epoch 5/15\n",
      "762/762 [==============================] - 1s 831us/step - loss: 0.8367 - accuracy: 0.6391 - val_loss: 0.8942 - val_accuracy: 0.6152\n",
      "Epoch 6/15\n",
      "762/762 [==============================] - 1s 858us/step - loss: 0.8291 - accuracy: 0.6411 - val_loss: 0.9023 - val_accuracy: 0.6119\n",
      "Epoch 7/15\n",
      "762/762 [==============================] - 1s 881us/step - loss: 0.8281 - accuracy: 0.6409 - val_loss: 0.8924 - val_accuracy: 0.6119\n",
      "Epoch 8/15\n",
      "762/762 [==============================] - 1s 832us/step - loss: 0.8254 - accuracy: 0.6442 - val_loss: 0.8968 - val_accuracy: 0.6157\n",
      "Epoch 9/15\n",
      "762/762 [==============================] - 1s 853us/step - loss: 0.8251 - accuracy: 0.6430 - val_loss: 0.8946 - val_accuracy: 0.6146\n",
      "Epoch 10/15\n",
      "762/762 [==============================] - 1s 854us/step - loss: 0.8213 - accuracy: 0.6453 - val_loss: 0.8960 - val_accuracy: 0.6207\n",
      "Epoch 11/15\n",
      "762/762 [==============================] - 1s 859us/step - loss: 0.8187 - accuracy: 0.6439 - val_loss: 0.8927 - val_accuracy: 0.6146\n",
      "Epoch 12/15\n",
      "762/762 [==============================] - 1s 853us/step - loss: 0.8196 - accuracy: 0.6443 - val_loss: 0.8874 - val_accuracy: 0.6135\n",
      "Epoch 13/15\n",
      "762/762 [==============================] - 1s 901us/step - loss: 0.8157 - accuracy: 0.6455 - val_loss: 0.8914 - val_accuracy: 0.6108\n",
      "Epoch 14/15\n",
      "762/762 [==============================] - 1s 862us/step - loss: 0.8161 - accuracy: 0.6534 - val_loss: 0.8915 - val_accuracy: 0.6141\n",
      "Epoch 15/15\n",
      "762/762 [==============================] - 1s 868us/step - loss: 0.8149 - accuracy: 0.6422 - val_loss: 0.8897 - val_accuracy: 0.6119\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_train, y_train = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8896603584289551\n",
      "Test accuracy: 0.6118746399879456\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "2173/2173 [==============================] - 2s 797us/step - loss: 1.3293 - accuracy: 0.3633 - val_loss: 1.2825 - val_accuracy: 0.4261\n",
      "Epoch 2/15\n",
      "2173/2173 [==============================] - 2s 737us/step - loss: 1.2801 - accuracy: 0.4114 - val_loss: 1.2721 - val_accuracy: 0.4508\n",
      "Epoch 3/15\n",
      "2173/2173 [==============================] - 2s 751us/step - loss: 1.2555 - accuracy: 0.4316 - val_loss: 1.2571 - val_accuracy: 0.4563\n",
      "Epoch 4/15\n",
      "2173/2173 [==============================] - 2s 718us/step - loss: 1.2262 - accuracy: 0.4492 - val_loss: 1.2226 - val_accuracy: 0.4662\n",
      "Epoch 5/15\n",
      "2173/2173 [==============================] - 2s 709us/step - loss: 1.2041 - accuracy: 0.4628 - val_loss: 1.2666 - val_accuracy: 0.4343\n",
      "Epoch 6/15\n",
      "2173/2173 [==============================] - 2s 762us/step - loss: 1.1727 - accuracy: 0.4804 - val_loss: 1.2128 - val_accuracy: 0.4629\n",
      "Epoch 7/15\n",
      "2173/2173 [==============================] - 2s 785us/step - loss: 1.1432 - accuracy: 0.4984 - val_loss: 1.2265 - val_accuracy: 0.4321\n",
      "Epoch 8/15\n",
      "2173/2173 [==============================] - 2s 761us/step - loss: 1.1199 - accuracy: 0.5097 - val_loss: 1.2618 - val_accuracy: 0.4211\n",
      "Epoch 9/15\n",
      "2173/2173 [==============================] - 2s 706us/step - loss: 1.0930 - accuracy: 0.5272 - val_loss: 1.2007 - val_accuracy: 0.4535\n",
      "Epoch 10/15\n",
      "2173/2173 [==============================] - 1s 649us/step - loss: 1.0783 - accuracy: 0.5302 - val_loss: 1.2413 - val_accuracy: 0.3997\n",
      "Epoch 11/15\n",
      "2173/2173 [==============================] - 1s 672us/step - loss: 1.0532 - accuracy: 0.5482 - val_loss: 1.2373 - val_accuracy: 0.4112\n",
      "Epoch 12/15\n",
      "2173/2173 [==============================] - 1s 675us/step - loss: 1.0384 - accuracy: 0.5572 - val_loss: 1.2240 - val_accuracy: 0.3947\n",
      "Epoch 13/15\n",
      "2173/2173 [==============================] - 1s 681us/step - loss: 1.0192 - accuracy: 0.5574 - val_loss: 1.1546 - val_accuracy: 0.4893\n",
      "Epoch 14/15\n",
      "2173/2173 [==============================] - 1s 680us/step - loss: 1.0033 - accuracy: 0.5696 - val_loss: 1.2751 - val_accuracy: 0.3821\n",
      "Epoch 15/15\n",
      "2173/2173 [==============================] - 2s 700us/step - loss: 0.9890 - accuracy: 0.5753 - val_loss: 1.2838 - val_accuracy: 0.3738\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "sm = SMOTE( random_state=23)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.283820629119873\n",
      "Test accuracy: 0.37383177876472473\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
