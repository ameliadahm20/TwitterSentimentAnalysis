{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product_</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lemmatizer_tweets</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vs_neg</th>\n",
       "      <th>vs_neu</th>\n",
       "      <th>vs_pos</th>\n",
       "      <th>vs_compound</th>\n",
       "      <th>nrc_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>henry_sentiment</th>\n",
       "      <th>huliu_sentiment</th>\n",
       "      <th>jockers_sentiment</th>\n",
       "      <th>lm_sentiment</th>\n",
       "      <th>senticnet_sentiment</th>\n",
       "      <th>sentiword_sentiment</th>\n",
       "      <th>socal_sentiment</th>\n",
       "      <th>product_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley83 have 3G iPhone 3 hr tweeting RISE Aus...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09520</td>\n",
       "      <td>-0.221875</td>\n",
       "      <td>-1.192154</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "      <td>jessedee Know fludapp Awesome iPad iPhone app ...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2.177190</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['swonderlin', 'not', 'wait', 'iPad', '2', 'al...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "      <td>swonderlin not wait iPad 2 also should sale do...</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.30550</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['sxsw', 'hope', 'year', 'festival', 't', 'cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "      <td>sxsw hope year festival t crashy this year iPh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.841547</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "      <td>sxtxstate great stuff Fri SXSW Marissa Mayer G...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55125</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.554026</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet            product_  \\\n",
       "0  ['wesley83', 'have', '3G', 'iPhone', '3', 'hrs...              iPhone   \n",
       "1  ['jessedee', 'Know', 'fludapp', 'Awesome', 'iP...  iPad or iPhone App   \n",
       "2  ['swonderlin', 'not', 'wait', 'iPad', '2', 'al...                iPad   \n",
       "3  ['sxsw', 'hope', 'year', 'festival', 't', 'cra...  iPad or iPhone App   \n",
       "4  ['sxtxstate', 'great', 'stuff', 'Fri', 'SXSW',...              Google   \n",
       "\n",
       "   emotion                                  lemmatizer_tweets  \\\n",
       "0        0  wesley83 have 3G iPhone 3 hr tweeting RISE Aus...   \n",
       "1        1  jessedee Know fludapp Awesome iPad iPhone app ...   \n",
       "2        1  swonderlin not wait iPad 2 also should sale do...   \n",
       "3        0  sxsw hope year festival t crashy this year iPh...   \n",
       "4        1  sxtxstate great stuff Fri SXSW Marissa Mayer G...   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  vs_neg  vs_neu  vs_pos  \\\n",
       "0          -0.200000               0.400000   0.223   0.777   0.000   \n",
       "1           0.466667               0.933333   0.000   0.528   0.472   \n",
       "2          -0.155556               0.288889   0.000   1.000   0.000   \n",
       "3           0.000000               0.000000   0.000   0.596   0.404   \n",
       "4           0.800000               0.750000   0.000   0.796   0.204   \n",
       "\n",
       "   vs_compound  nrc_sentiment  gi_sentiment  henry_sentiment  huliu_sentiment  \\\n",
       "0      -0.6486            0.0     -0.333333              0.0             -1.0   \n",
       "1       0.9100            1.0      1.000000              0.0              1.0   \n",
       "2       0.0000           -1.0     -1.000000             -1.0             -1.0   \n",
       "3       0.7269            1.0      1.000000              0.0              0.0   \n",
       "4       0.6249            0.0      1.000000              0.0              1.0   \n",
       "\n",
       "   jockers_sentiment  lm_sentiment  senticnet_sentiment  sentiword_sentiment  \\\n",
       "0          -1.000000           0.0             -0.09520            -0.221875   \n",
       "1           0.416667           0.0              0.47500             0.175000   \n",
       "2          -0.625000          -1.0             -0.30550            -0.289062   \n",
       "3           0.500000           0.0              0.07160             0.250000   \n",
       "4           0.500000           1.0              0.55125             0.083333   \n",
       "\n",
       "   socal_sentiment product_agg  \n",
       "0        -1.192154       Apple  \n",
       "1         2.177190       Apple  \n",
       "2        -1.000000       Apple  \n",
       "3         2.841547       Apple  \n",
       "4         1.554026      Google  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('../data/dataframe.csv', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update output\n",
    "df['emotion'] = np.where(df['emotion'] == 4, 2, df['emotion'])\n",
    "# specify data and target\n",
    "data = df.drop(columns=['emotion', 'tweet', 'product_', 'lemmatizer_tweets', 'product_agg'])\n",
    "target = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 15)\n",
      "(1819, 15)\n",
      "(7273,)\n",
      "(1819,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "# look at shpae of input\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "910/910 [==============================] - 1s 983us/step - loss: 0.9463 - accuracy: 0.5867 - val_loss: 0.9236 - val_accuracy: 0.5728\n",
      "Epoch 2/15\n",
      "910/910 [==============================] - 1s 708us/step - loss: 0.8883 - accuracy: 0.6053 - val_loss: 0.9010 - val_accuracy: 0.5976\n",
      "Epoch 3/15\n",
      "910/910 [==============================] - 1s 715us/step - loss: 0.8731 - accuracy: 0.6055 - val_loss: 0.8902 - val_accuracy: 0.6086\n",
      "Epoch 4/15\n",
      "910/910 [==============================] - 1s 707us/step - loss: 0.8668 - accuracy: 0.6108 - val_loss: 0.8888 - val_accuracy: 0.6102\n",
      "Epoch 5/15\n",
      "910/910 [==============================] - 1s 748us/step - loss: 0.8651 - accuracy: 0.6120 - val_loss: 0.8947 - val_accuracy: 0.5970\n",
      "Epoch 6/15\n",
      "910/910 [==============================] - 1s 734us/step - loss: 0.8592 - accuracy: 0.6091 - val_loss: 0.8875 - val_accuracy: 0.6047\n",
      "Epoch 7/15\n",
      "910/910 [==============================] - 1s 710us/step - loss: 0.8573 - accuracy: 0.6212 - val_loss: 0.8834 - val_accuracy: 0.6174\n",
      "Epoch 8/15\n",
      "910/910 [==============================] - 1s 713us/step - loss: 0.8560 - accuracy: 0.6182 - val_loss: 0.8887 - val_accuracy: 0.6185\n",
      "Epoch 9/15\n",
      "910/910 [==============================] - 1s 710us/step - loss: 0.8522 - accuracy: 0.6205 - val_loss: 0.8829 - val_accuracy: 0.6119\n",
      "Epoch 10/15\n",
      "910/910 [==============================] - 1s 735us/step - loss: 0.8532 - accuracy: 0.6198 - val_loss: 0.8810 - val_accuracy: 0.6108\n",
      "Epoch 11/15\n",
      "910/910 [==============================] - 1s 709us/step - loss: 0.8497 - accuracy: 0.6141 - val_loss: 0.8828 - val_accuracy: 0.6069\n",
      "Epoch 12/15\n",
      "910/910 [==============================] - 1s 725us/step - loss: 0.8492 - accuracy: 0.6193 - val_loss: 0.8888 - val_accuracy: 0.6086\n",
      "Epoch 13/15\n",
      "910/910 [==============================] - 1s 717us/step - loss: 0.8483 - accuracy: 0.6165 - val_loss: 0.8848 - val_accuracy: 0.6091\n",
      "Epoch 14/15\n",
      "910/910 [==============================] - 1s 711us/step - loss: 0.8483 - accuracy: 0.6183 - val_loss: 0.8864 - val_accuracy: 0.6119\n",
      "Epoch 15/15\n",
      "910/910 [==============================] - 1s 742us/step - loss: 0.8457 - accuracy: 0.6222 - val_loss: 0.8815 - val_accuracy: 0.6157\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8815038204193115\n",
      "Test accuracy: 0.6157229542732239\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization tool\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"Sentiment Neural Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 2: Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "762/762 [==============================] - 1s 949us/step - loss: 0.9292 - accuracy: 0.6181 - val_loss: 0.9111 - val_accuracy: 0.5926\n",
      "Epoch 2/15\n",
      "762/762 [==============================] - 1s 779us/step - loss: 0.8630 - accuracy: 0.6353 - val_loss: 0.9058 - val_accuracy: 0.6042\n",
      "Epoch 3/15\n",
      "762/762 [==============================] - 1s 783us/step - loss: 0.8520 - accuracy: 0.6358 - val_loss: 0.9029 - val_accuracy: 0.6014\n",
      "Epoch 4/15\n",
      "762/762 [==============================] - 1s 749us/step - loss: 0.8418 - accuracy: 0.6430 - val_loss: 0.9151 - val_accuracy: 0.6042\n",
      "Epoch 5/15\n",
      "762/762 [==============================] - 1s 760us/step - loss: 0.8386 - accuracy: 0.6407 - val_loss: 0.8933 - val_accuracy: 0.6080\n",
      "Epoch 6/15\n",
      "762/762 [==============================] - 1s 756us/step - loss: 0.8310 - accuracy: 0.6363 - val_loss: 0.8895 - val_accuracy: 0.6086\n",
      "Epoch 7/15\n",
      "762/762 [==============================] - 1s 797us/step - loss: 0.8309 - accuracy: 0.6391 - val_loss: 0.8884 - val_accuracy: 0.6053\n",
      "Epoch 8/15\n",
      "762/762 [==============================] - 1s 761us/step - loss: 0.8277 - accuracy: 0.6445 - val_loss: 0.8905 - val_accuracy: 0.6135\n",
      "Epoch 9/15\n",
      "762/762 [==============================] - 1s 784us/step - loss: 0.8210 - accuracy: 0.6457 - val_loss: 0.8986 - val_accuracy: 0.6152\n",
      "Epoch 10/15\n",
      "762/762 [==============================] - 1s 774us/step - loss: 0.8194 - accuracy: 0.6440 - val_loss: 0.8866 - val_accuracy: 0.6102\n",
      "Epoch 11/15\n",
      "762/762 [==============================] - 1s 783us/step - loss: 0.8179 - accuracy: 0.6486 - val_loss: 0.8967 - val_accuracy: 0.6102\n",
      "Epoch 12/15\n",
      "762/762 [==============================] - 1s 804us/step - loss: 0.8160 - accuracy: 0.6503 - val_loss: 0.8862 - val_accuracy: 0.6113\n",
      "Epoch 13/15\n",
      "762/762 [==============================] - 1s 824us/step - loss: 0.8153 - accuracy: 0.6527 - val_loss: 0.8845 - val_accuracy: 0.6130\n",
      "Epoch 14/15\n",
      "762/762 [==============================] - 1s 772us/step - loss: 0.8148 - accuracy: 0.6470 - val_loss: 0.8869 - val_accuracy: 0.6201\n",
      "Epoch 15/15\n",
      "762/762 [==============================] - 1s 759us/step - loss: 0.8102 - accuracy: 0.6511 - val_loss: 0.8907 - val_accuracy: 0.6157\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_train, y_train = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8907440900802612\n",
      "Test accuracy: 0.6157229542732239\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 22,204\n",
      "Trainable params: 22,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "2173/2173 [==============================] - 2s 719us/step - loss: 1.3380 - accuracy: 0.3520 - val_loss: 1.3180 - val_accuracy: 0.4338\n",
      "Epoch 2/15\n",
      "2173/2173 [==============================] - 1s 670us/step - loss: 1.2886 - accuracy: 0.4014 - val_loss: 1.2852 - val_accuracy: 0.4415\n",
      "Epoch 3/15\n",
      "2173/2173 [==============================] - 1s 677us/step - loss: 1.2561 - accuracy: 0.4254 - val_loss: 1.2714 - val_accuracy: 0.4579\n",
      "Epoch 4/15\n",
      "2173/2173 [==============================] - 1s 643us/step - loss: 1.2313 - accuracy: 0.4446 - val_loss: 1.3110 - val_accuracy: 0.3997\n",
      "Epoch 5/15\n",
      "2173/2173 [==============================] - 1s 649us/step - loss: 1.2114 - accuracy: 0.4544 - val_loss: 1.2206 - val_accuracy: 0.4706\n",
      "Epoch 6/15\n",
      "2173/2173 [==============================] - 1s 652us/step - loss: 1.1849 - accuracy: 0.4723 - val_loss: 1.2781 - val_accuracy: 0.3821\n",
      "Epoch 7/15\n",
      "2173/2173 [==============================] - 1s 651us/step - loss: 1.1631 - accuracy: 0.4859 - val_loss: 1.2748 - val_accuracy: 0.3766\n",
      "Epoch 8/15\n",
      "2173/2173 [==============================] - 1s 658us/step - loss: 1.1378 - accuracy: 0.5013 - val_loss: 1.2534 - val_accuracy: 0.4437\n",
      "Epoch 9/15\n",
      "2173/2173 [==============================] - 1s 677us/step - loss: 1.1166 - accuracy: 0.5128 - val_loss: 1.2799 - val_accuracy: 0.3892\n",
      "Epoch 10/15\n",
      "2173/2173 [==============================] - 1s 656us/step - loss: 1.0949 - accuracy: 0.5230 - val_loss: 1.2136 - val_accuracy: 0.4579\n",
      "Epoch 11/15\n",
      "2173/2173 [==============================] - 1s 638us/step - loss: 1.0721 - accuracy: 0.5339 - val_loss: 1.2814 - val_accuracy: 0.3639\n",
      "Epoch 12/15\n",
      "2173/2173 [==============================] - 1s 639us/step - loss: 1.0533 - accuracy: 0.5433 - val_loss: 1.1868 - val_accuracy: 0.4596\n",
      "Epoch 13/15\n",
      "2173/2173 [==============================] - 1s 635us/step - loss: 1.0366 - accuracy: 0.5526 - val_loss: 1.1561 - val_accuracy: 0.4854\n",
      "Epoch 14/15\n",
      "2173/2173 [==============================] - 1s 635us/step - loss: 1.0205 - accuracy: 0.5571 - val_loss: 1.1947 - val_accuracy: 0.4200\n",
      "Epoch 15/15\n",
      "2173/2173 [==============================] - 1s 645us/step - loss: 0.9992 - accuracy: 0.5711 - val_loss: 1.1562 - val_accuracy: 0.4788\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state=1)\n",
    "\n",
    "sm = SMOTE( random_state=23)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "batch_size = 8 # how many folds to separate data\n",
    "num_classes = 4 # how many classes in outcomes\n",
    "epochs = 15\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype('uint8')\n",
    "y_test = y_test.astype('uint8')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# specifying the model structure\n",
    "model = Sequential()\n",
    "\n",
    "# specify the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(15,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# # specify the third layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# specify the output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # switched linear to sofmax\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.156239628791809\n",
      "Test accuracy: 0.47883450984954834\n"
     ]
    }
   ],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
